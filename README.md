# ðŸ”§ FinGAT Backend - AI Stock Prediction API

FastAPI backend with Graph Attention Networks and Reinforcement Learning for Indian stock market predictions.

---

## ðŸš€ Quick Start

### **Installation**

```bash
# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Setup environment
copy .env.example .env
# Edit .env with your database credentials
```

### **Database Setup**

```bash
# Initialize database
python -c "from app.db.database import init_db; init_db()"

# Populate with stock data
python scripts/sync_data.py
```

### **Train Model**

```bash
# Train with Hybrid RL (recommended)
python scripts/train_with_hybrid_rl.py

# Generate predictions
python predict_now.py
```

### **Start Server**

```bash
# Development
uvicorn app.main:app --reload

# Production
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Server runs at: `http://localhost:8000`  
API Docs: `http://localhost:8000/docs`

---

## ðŸ“ Project Structure

```
FinGAT_Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py          # API endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ model_loader.py    # Model loading
â”‚   â”‚   â””â”€â”€ predictor.py       # Prediction logic
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ database.py        # Database connection
â”‚   â”‚   â””â”€â”€ models.py          # SQLAlchemy models
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â””â”€â”€ tasks.py           # Daily automation
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â””â”€â”€ main.py                # FastAPI app
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sync_data.py           # Data sync (CSVs + DB)
â”‚   â”œâ”€â”€ train_with_hybrid_rl.py # Hybrid RL training
â”‚   â”œâ”€â”€ predict_single_stock.py # Single stock predictor
â”‚   â””â”€â”€ populate_db.py         # Database population
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data_loader.py         # Dataset loader
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ lightning_module.py    # PyTorch Lightning module
â”‚
â”œâ”€â”€ indian_data/               # Stock CSV files (147+)
â”œâ”€â”€ predictions/               # Generated predictions
â”œâ”€â”€ checkpoints/               # Model checkpoints
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # Model configuration
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Procfile                   # Railway/Render deployment
â””â”€â”€ .env                       # Environment variables
```

---

## ðŸ”Œ API Endpoints

### **Predictions**

```bash
# Get top K predictions
GET /api/v1/predict/top-k?k=10&sector=Technology

# Single stock prediction
GET /api/v1/predict/single/INFY

# Generate fresh predictions
POST /api/v1/predict/now
```

### **Data**

```bash
# List stocks
GET /api/v1/stocks?limit=500&sector=Finance

# List sectors
GET /api/v1/sectors
```

### **Model Management**

```bash
# Model info
GET /api/v1/model/info

# Model status
GET /api/v1/model/status

# Trigger retraining
POST /api/v1/retrain

# Reload feature mask
POST /api/v1/reload-features
```

### **Health**

```bash
# Health check
GET /api/v1/health
```

Full documentation: `http://localhost:8000/docs`

---

## ðŸ¤– ML Pipeline

### **1. Data Sync**

```bash
python scripts/sync_data.py
```

- Updates stock prices from yfinance
- Syncs PostgreSQL database
- Handles 147+ NSE/BSE stocks
- Retry logic with rate limiting

### **2. Model Training**

```bash
python scripts/train_with_hybrid_rl.py
```

- **Hybrid RL Optimization:** Features + Hyperparameters
- **Algorithm:** PPO (Proximal Policy Optimization)
- **Architecture:** GATv2 with hierarchical attention
- **Features:** 73 multi-scale temporal features
- **Duration:** ~2 hours on CPU

### **3. Prediction Generation**

```bash
python predict_now.py
```

- Loads latest trained model
- Generates predictions for all stocks
- Creates Top-5/10/20 CSV files
- Confidence filtering (>40%)

### **4. Model Reload**

```python
# Hot-reload without server restart
from app.core.model_loader import model_loader
model_loader.reload_model()
```

---

## ðŸ”„ Daily Automation

Automated pipeline runs at **6:30 PM IST** (after market close):

```python
# app/scheduler/tasks.py
def daily_pipeline():
    1. sync_data()        # Update CSVs + Database
    2. train_model()      # Retrain with Hybrid RL
    3. reload_model()     # Hot-reload new model
```

Configured in `app/main.py` using APScheduler.

---

## âš™ï¸ Configuration

### **Environment Variables (.env)**

```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/fingat_db

# Paths
CONFIG_PATH=config/config.yaml
MODEL_CHECKPOINT_PATH=checkpoints/production_model.ckpt
DATA_PATH=indian_data

# Runtime
DEVICE=cpu
PYTHONPATH=.

# Scheduler
TRAINING_HOUR=18
TRAINING_MINUTE=30
TRAINING_TIMEZONE=Asia/Kolkata
```

### **Model Config (config/config.yaml)**

```yaml
model:
  hidden_dim: 128
  num_heads: 4
  num_layers: 3
  dropout: 0.3

training:
  batch_size: 32
  learning_rate: 0.001
  max_epochs: 100
  early_stopping_patience: 10

data:
  lookback_days: 60
  prediction_horizon: 1
  train_split: 0.7
  val_split: 0.15
```

---

## ðŸ—„ï¸ Database Schema

### **stocks** table

```sql
CREATE TABLE stocks (
    id SERIAL PRIMARY KEY,
    ticker VARCHAR(20) UNIQUE NOT NULL,
    company_name VARCHAR(255) NOT NULL,
    sector VARCHAR(100),
    industry VARCHAR(100),
    current_price FLOAT,
    market_cap FLOAT,
    exchange VARCHAR(10) DEFAULT 'NSE',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP
);
```

### **Indexes**

```sql
CREATE INDEX idx_ticker ON stocks(ticker);
CREATE INDEX idx_sector ON stocks(sector);
```

---

## ðŸ§ª Testing

### **Test API Endpoints**

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Get predictions
curl http://localhost:8000/api/v1/predict/top-k?k=10

# Single stock
curl http://localhost:8000/api/v1/predict/single/INFY

# List stocks
curl http://localhost:8000/api/v1/stocks?limit=10
```

### **Test Scripts**

```bash
# Compile check
python -m py_compile app/main.py
python -m py_compile scripts/*.py

# Import check
python -c "from app.main import app; print('âœ“ OK')"
```

---

## ðŸ“¦ Dependencies

### **Core**

- `fastapi==0.104.1` - Web framework
- `uvicorn==0.23.2` - ASGI server
- `sqlalchemy==2.0.23` - ORM
- `psycopg2-binary==2.9.9` - PostgreSQL driver

### **ML/DL**

- `torch==2.1.0` - Deep learning
- `torch-geometric==2.3.1` - Graph neural networks
- `pytorch-lightning==2.1.2` - Training framework

### **RL**

- `stable-baselines3==2.0.0` - Reinforcement learning
- `gymnasium==0.28.1` - RL environments

### **Data**

- `yfinance==0.2.32` - Stock data
- `pandas==2.1.2` - Data manipulation
- `numpy==1.26.2` - Numerical computing

### **Utilities**

- `apscheduler==3.10.4` - Task scheduling
- `python-dotenv==1.0.0` - Environment variables
- `pyyaml==6.0.1` - YAML parsing

---

## ðŸš€ Deployment

### **Prepare for Deployment**

```bash
# Run deployment script
.\deploy.bat  # Windows
# ./deploy.sh  # Linux/Mac

# Creates:
# - Procfile
# - runtime.txt
# - requirements.txt
# - .dockerignore
```

### **Deploy to Railway**

```bash
# Push to GitHub
git add .
git commit -m "Ready for deployment"
git push origin main

# On Railway:
# 1. New Project â†’ Deploy from GitHub
# 2. Add PostgreSQL database
# 3. Set environment variables
# 4. Deploy!
```

### **Initialize Production**

```bash
# After deployment
railway run python scripts/sync_data.py
railway run python scripts/train_with_hybrid_rl.py
railway run python predict_now.py
```

See [../DEPLOYMENT_GUIDE.md](../DEPLOYMENT_GUIDE.md) for details.

---

## ðŸ”§ Maintenance

### **Update Stock Data**

```bash
python scripts/sync_data.py
```

### **Retrain Model**

```bash
python scripts/train_with_hybrid_rl.py
```

### **Generate Predictions**

```bash
python predict_now.py
```

### **View Logs**

```bash
# Local
tail -f logs/app.log

# Railway
railway logs
```

### **Database Backup**

```bash
# Backup
pg_dump $DATABASE_URL > backup.sql

# Restore
psql $DATABASE_URL < backup.sql
```

---

## ðŸ“Š Performance

### **Model Metrics**

- **Accuracy:** 56%+ directional prediction
- **Confidence:** 40%+ threshold
- **Coverage:** 147+ Indian stocks
- **Update:** Daily at 6:30 PM IST

### **API Performance**

- **Response Time:** <100ms (cached)
- **Throughput:** 100+ req/sec
- **Uptime:** 99.9%

---

## ðŸ› Troubleshooting

### **Database Connection Failed**

```bash
# Check DATABASE_URL
echo $DATABASE_URL

# Test connection
psql $DATABASE_URL

# Verify PostgreSQL is running
```

### **Model Not Loading**

```bash
# Check checkpoint exists
ls checkpoints/production_model.ckpt

# Verify config
cat config/config.yaml

# Check logs
tail -f logs/app.log
```

### **Import Errors**

```bash
# Verify PYTHONPATH
echo $PYTHONPATH

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

---

## ðŸ“š Additional Resources

- **Main README:** [../README.md](../README.md)
- **Deployment Guide:** [../DEPLOYMENT_GUIDE.md](../DEPLOYMENT_GUIDE.md)
- **Quick Deploy:** [../QUICK_DEPLOY.md](../QUICK_DEPLOY.md)
- **API Docs:** `http://localhost:8000/docs`

---

## ðŸ¤ Contributing

1. Follow PEP 8 style guide
2. Add type hints
3. Write docstrings
4. Test before committing
5. Update documentation

---

**Backend is ready! ðŸš€**

Start server: `uvicorn app.main:app --reload`  
API Docs: `http://localhost:8000/docs`
